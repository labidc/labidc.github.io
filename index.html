<!DOCTYPE html>












  


<html class="theme-next pisces use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">


























<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=7.0.1">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.0.1">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.0.1">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.0.1">


  <link rel="mask-icon" href="/images/logo.svg?v=7.0.1" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '7.0.1',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="喜欢研究技术的本质">
<meta name="keywords" content="JAVA,JavaScript,C#,Spring,Spring Cloud,领域驱动开发">
<meta property="og:type" content="website">
<meta property="og:title" content="老码的技术仓库">
<meta property="og:url" content="https://labidc.github.io/index.html">
<meta property="og:site_name" content="老码的技术仓库">
<meta property="og:description" content="喜欢研究技术的本质">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="老码的技术仓库">
<meta name="twitter:description" content="喜欢研究技术的本质">






  <link rel="canonical" href="https://labidc.github.io/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>老码的技术仓库</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>
    <a href="https://github.com/labidc" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewbox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">老码的技术仓库</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">不知道说些什么</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home menu-item-active">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://labidc.github.io/2019/05/31/harbor-helm安装/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Labidc">
      <meta itemprop="description" content="喜欢研究技术的本质">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="老码的技术仓库">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/05/31/harbor-helm安装/" class="post-title-link" itemprop="url">harbor-helm安装</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-31 22:09:32 / 修改时间：22:33:03" itemprop="dateCreated datePublished" datetime="2019-05-31T22:09:32+08:00">2019-05-31</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Kubernetes/" itemprop="url" rel="index"><span itemprop="name">Kubernetes</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Harbor-是容器仓库，所以用到容器的架构，都会自己创建私有的仓库，废话少说，这里讲讲我遇到的坑。本文针对安装了Helm-的环境安装Harbor-并把Habor部署到k8s-所以没有安装Helm请查看我上一篇文章"><a href="#Harbor-是容器仓库，所以用到容器的架构，都会自己创建私有的仓库，废话少说，这里讲讲我遇到的坑。本文针对安装了Helm-的环境安装Harbor-并把Habor部署到k8s-所以没有安装Helm请查看我上一篇文章" class="headerlink" title="Harbor 是容器仓库，所以用到容器的架构，都会自己创建私有的仓库，废话少说，这里讲讲我遇到的坑。本文针对安装了Helm 的环境安装Harbor, 并把Habor部署到k8s, 所以没有安装Helm请查看我上一篇文章"></a>Harbor 是容器仓库，所以用到容器的架构，都会自己创建私有的仓库，废话少说，这里讲讲我遇到的坑。本文针对安装了Helm 的环境安装Harbor, 并把Habor部署到k8s, 所以没有安装Helm请查看我上一篇文章</h2><p>下载harbor源码，并进入该目录</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/goharbor/harbor-helm.git</span><br><span class="line">cd harbor-helm/</span><br></pre></td></tr></table></figure>
<ul>
<li><p>这一步非常重要，如果您只是本地测试环境，没有配置dns服务，没有公网域名访问的需求，请先修改配置文件, values.yaml 可以设置密码，等一下安装配置参数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vim values.yaml</span><br><span class="line">#  expose.type 配置 修改成 nodePort模式，其实配置文件里有说明，可以详细看看配置的不同的区别</span><br></pre></td></tr></table></figure>
</li>
<li><p>这一步也比较重要，默认helm没有权限创建持久卷(PV)，但是该harbor-helm编排中用到了数据库,redis,等应用作为服务的存储，并用到了持久卷申请（PVC）。 所以这里要为harbor提前创建好持久卷(PV)供harbor-helm使用</p>
</li>
<li>这里我使用的是 nfs ,作为远程服务器存储使用方案，也是k8s常用的持久卷解决方案</li>
<li>安装nfs看这篇文章就行了, 注意权限问题，注意，只需要看如何安装与如何配置 <a href="https://blog.csdn.net/networken/article/details/86697018" target="_blank" rel="noopener">传送门过去查看</a></li>
</ul>
<h2 id="nfs安装完成之后（可以是非master的其他节点安装）"><a href="#nfs安装完成之后（可以是非master的其他节点安装）" class="headerlink" title="nfs安装完成之后（可以是非master的其他节点安装）"></a>nfs安装完成之后（可以是非master的其他节点安装）</h2><p>在k8s上为harbor 创建 pv持久卷<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">for i in &#123;1..9&#125;; do</span><br><span class="line">cat &lt;&lt;EOF | kubectl apply -f -</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolume</span><br><span class="line">metadata:</span><br><span class="line">  name: pv00$&#123;i&#125;</span><br><span class="line">spec:</span><br><span class="line">  capacity:</span><br><span class="line">    storage: 100Gi</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteOnce #需要注意</span><br><span class="line">  persistentVolumeReclaimPolicy: Recycle</span><br><span class="line">  nfs:</span><br><span class="line">    # 注意这里是nfs服务上的磁盘路径，并给予了nfs权限</span><br><span class="line">    path: /volume1/harbor/nfs$&#123;i&#125;</span><br><span class="line">    # 注意这里的ip是地址nfs服务器的ip</span><br><span class="line">    server: 192.168.2.4</span><br><span class="line">EOF</span><br><span class="line">done</span><br></pre></td></tr></table></figure></p>
<h2 id="最后安装进入harbor-helm-源码目录"><a href="#最后安装进入harbor-helm-源码目录" class="headerlink" title="最后安装进入harbor-helm 源码目录"></a>最后安装进入harbor-helm 源码目录</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm install --name harbor-v1 .  --wait --timeout 1500 --debug --namespace harbor</span><br></pre></td></tr></table></figure>
          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://labidc.github.io/2019/05/31/Kubernetes-helm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Labidc">
      <meta itemprop="description" content="喜欢研究技术的本质">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="老码的技术仓库">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/05/31/Kubernetes-helm/" class="post-title-link" itemprop="url">Kubernetes 安装 helm 工具</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-31 21:40:48 / 修改时间：22:38:37" itemprop="dateCreated datePublished" datetime="2019-05-31T21:40:48+08:00">2019-05-31</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Kubernetes/" itemprop="url" rel="index"><span itemprop="name">Kubernetes</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>基于微服务机构，跑不掉使用容器，使用容器就会有用到容器管理工具Kubernetes, 用了Kubernetes，就会使用更高级的工具帮助Kubernetes 的编排。这里比较适合的工具就是Helm，Helm还提供了kubernetes上的软件部署，删除，升级，回滚应用的强大功能。<br>其他的废话不多说，Helm 原理也就多说了，网上资料很多。</p>
<h2 id="安装-helm-工具"><a href="#安装-helm-工具" class="headerlink" title="安装 helm 工具"></a>安装 helm 工具</h2><p>git仓库地址：<a href="https://github.com/helm/helm/releases" target="_blank" rel="noopener">https://github.com/helm/helm/releases</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">wget https://storage.googleapis.com/kubernetes-helm/helm-v2.14.0-linux-amd64.tar.gz  </span><br><span class="line">tar xf helm-v2.14.0-linux-amd64.tar.gz </span><br><span class="line">cp linux-amd64/helm linux-amd64/tiller /usr/local/bin/</span><br><span class="line">```	</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">这个时候使用命令，会打印client和server的版本由于这里只安装了client, 所以server版本无法获取</span><br></pre></td></tr></table></figure>
<p>helm version<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">安装server端口</span><br></pre></td></tr></table></figure></p>
<p>helm init –upgrade -i registry.cn-hangzhou.aliyuncs.com/google_containers/tiller:v2.14.0 –stable-repo-url <a href="https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts" target="_blank" rel="noopener">https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">这里需要注意的是client和server版本的一致性, 再使用命令看看client和server是已经都OK了</span><br></pre></td></tr></table></figure></p>
<p>helm version<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">现在需要使用tiller对k8s进行管理和部署，需要权限的, 添加账号与设置权限</span><br></pre></td></tr></table></figure></p>
<p>kubectl create serviceaccount –namespace kube-system tiller</p>
<p>kubectl create clusterrolebinding tiller-cluster-rule –clusterrole=cluster-admin –serviceaccount=kube-system:tiller</p>
<p>kubectl patch deploy –namespace kube-system tiller-deploy -p ‘{“spec”:{“template”:{“spec”:{“serviceAccount”:”tiller”}}}}’<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">现在在k8s容器里多了一个服务, 通过下面方式查看</span><br></pre></td></tr></table></figure></p>
<p>kubectl -n kube-system get pods|grep tiller<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">需要使用helm, 拉取一些制作好的应用编排，与yum一样，也可以修改一个下镜像地址，才能顺利使用。也就是更新 charts 仓库</span><br></pre></td></tr></table></figure></p>
<h1 id="先移除原先的仓库"><a href="#先移除原先的仓库" class="headerlink" title="先移除原先的仓库"></a>先移除原先的仓库</h1><p>helm repo remove stable</p>
<h1 id="添加新的仓库地址"><a href="#添加新的仓库地址" class="headerlink" title="添加新的仓库地址"></a>添加新的仓库地址</h1><p>helm repo add stable <a href="https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts" target="_blank" rel="noopener">https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts</a></p>
<h1 id="更新仓库"><a href="#更新仓库" class="headerlink" title="更新仓库"></a>更新仓库</h1><p>helm repo update<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">* helm 安装服务方式有两种，直接通过仓库里拉取安装</span><br><span class="line">* 通过本地文件里的编排文件进行安装</span><br></pre></td></tr></table></figure></p>
<h1 id="比如安装nginx-拉取镜像模式"><a href="#比如安装nginx-拉取镜像模式" class="headerlink" title="比如安装nginx, 拉取镜像模式"></a>比如安装nginx, 拉取镜像模式</h1><p>helm install stable/nginx-ingress –set controller.hostNetwork=true，rbac.create=true</p>
<h1 id="比如安装本地下载好的编排文件，进入编排文件夹，还可以创建依赖文件一起下载安装-requirements-yaml"><a href="#比如安装本地下载好的编排文件，进入编排文件夹，还可以创建依赖文件一起下载安装-requirements-yaml" class="headerlink" title="比如安装本地下载好的编排文件，进入编排文件夹，还可以创建依赖文件一起下载安装(requirements.yaml )"></a>比如安装本地下载好的编排文件，进入编排文件夹，还可以创建依赖文件一起下载安装(requirements.yaml )</h1><p>helm install –name ${部署的服务名称} .  –wait –timeout 1500 –debug –namespace harbor<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">* 删除部署的服务</span><br></pre></td></tr></table></figure></p>
<p>helm delete –purge ${部署的服务名称}<br><code>`</code></p>
<p>helm 其实还有 templates，可以定义变量，请自行查阅相关资料</p>
<h3 id="本文中出现的-说明-，表示变量，你可以根据你需要修改"><a href="#本文中出现的-说明-，表示变量，你可以根据你需要修改" class="headerlink" title="本文中出现的${说明}，表示变量，你可以根据你需要修改"></a>本文中出现的${说明}，表示变量，你可以根据你需要修改</h3><h3 id="比如-helm-delete-–purge-部署的服务名称"><a href="#比如-helm-delete-–purge-部署的服务名称" class="headerlink" title="比如 helm delete –purge ${部署的服务名称}"></a>比如 helm delete –purge ${部署的服务名称}</h3><h3 id="helm-delete-–purge-my-server"><a href="#helm-delete-–purge-my-server" class="headerlink" title="helm delete –purge my_server"></a>helm delete –purge my_server</h3><h2 id="helm-其实还有打包命令，升级服务命令，回退服务命令，请自己去查阅相关资料，或者查看官方git文档"><a href="#helm-其实还有打包命令，升级服务命令，回退服务命令，请自己去查阅相关资料，或者查看官方git文档" class="headerlink" title="helm 其实还有打包命令，升级服务命令，回退服务命令，请自己去查阅相关资料，或者查看官方git文档"></a>helm 其实还有打包命令，升级服务命令，回退服务命令，请自己去查阅相关资料，或者查看官方git文档</h2>
          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://labidc.github.io/2019/05/30/Centos7-Kubernetes-1-14-2-集群安装/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Labidc">
      <meta itemprop="description" content="喜欢研究技术的本质">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="老码的技术仓库">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/05/30/Centos7-Kubernetes-1-14-2-集群安装/" class="post-title-link" itemprop="url">Centos7-Kubernetes-1.14.2-集群安装</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-30 22:42:13" itemprop="dateCreated datePublished" datetime="2019-05-30T22:42:13+08:00">2019-05-30</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-05-31 00:21:12" itemprop="dateModified" datetime="2019-05-31T00:21:12+08:00">2019-05-31</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Kubernetes/" itemprop="url" rel="index"><span itemprop="name">Kubernetes</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>微服务架构的时代，大量的服务一定会用到Doker或者 Rocket（rkt）容器工具做基础虚拟化工具，但是对于虚拟化的集群管理，虽然工具很多，比如Swarm，还有就是大名鼎鼎的Kubernetes, 今天讲解的就是Centos7+Kubernetes+Docker 集群搭建安装方案。</p>
<h2 id="本搭建基础环境"><a href="#本搭建基础环境" class="headerlink" title="本搭建基础环境"></a>本搭建基础环境</h2><ul>
<li>服务器 esxi 6.5 环境</li>
<li>创建两台虚拟机</li>
</ul>
<table>
<thead>
<tr>
<th>服务器主机名(hostname)</th>
<th>IP地址</th>
<th>操作系统版本</th>
</tr>
</thead>
<tbody>
<tr>
<td>k8s-master</td>
<td>192.168.2.163</td>
<td>Centos7.6</td>
</tr>
<tr>
<td>k8s-node</td>
<td>192.168.2.197</td>
<td>Centos7.6</td>
</tr>
</tbody>
</table>
<hr>
<h2 id="所有主机需要安装步骤"><a href="#所有主机需要安装步骤" class="headerlink" title="所有主机需要安装步骤"></a>所有主机需要安装步骤</h2><h3 id="安装Docker"><a href="#安装Docker" class="headerlink" title="安装Docker"></a>安装Docker</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum update -y</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install -y docker</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl enable docker &amp;&amp; sudo systemctl start docker</span><br></pre></td></tr></table></figure>
<h3 id="安装-Kubernetes"><a href="#安装-Kubernetes" class="headerlink" title="安装 Kubernetes"></a>安装 Kubernetes</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br><span class="line">repo_gpgcheck=0</span><br><span class="line">gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg</span><br><span class="line">       http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<h3 id="关闭SELinux"><a href="#关闭SELinux" class="headerlink" title="关闭SELinux"></a>关闭SELinux</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo setenforce 0</span><br><span class="line">sudo sed -i &apos;s/^SELINUX=enforcing$/SELINUX=permissive/&apos; /etc/selinux/config</span><br></pre></td></tr></table></figure>
<h3 id="安装-kubelet、kubeadm、kubectl"><a href="#安装-kubelet、kubeadm、kubectl" class="headerlink" title="安装 kubelet、kubeadm、kubectl"></a>安装 kubelet、kubeadm、kubectl</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes</span><br></pre></td></tr></table></figure>
<h3 id="启动-kubelet-服务"><a href="#启动-kubelet-服务" class="headerlink" title="启动 kubelet 服务"></a>启动 kubelet 服务</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl enable kubelet &amp;&amp; sudo systemctl start kubelet</span><br></pre></td></tr></table></figure>
<h3 id="关闭sawp"><a href="#关闭sawp" class="headerlink" title="关闭sawp"></a>关闭sawp</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo swapoff -a</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="Master-节点安装步骤"><a href="#Master-节点安装步骤" class="headerlink" title="Master 节点安装步骤"></a>Master 节点安装步骤</h2><h3 id="防火墙端口设置"><a href="#防火墙端口设置" class="headerlink" title="防火墙端口设置"></a>防火墙端口设置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --permanent --add-port=6443/tcp &amp;&amp; sudo firewall-cmd --permanent --add-port=10250/tcp &amp;&amp; sudo firewall-cmd --reload</span><br></pre></td></tr></table></figure>
<h3 id="设置-IPTables"><a href="#设置-IPTables" class="headerlink" title="设置 IPTables"></a>设置 IPTables</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo bash -c &apos;cat &lt;&lt;EOF &gt;  /etc/sysctl.d/k8s.conf</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">EOF&apos;</span><br></pre></td></tr></table></figure>
<p>执行下面命令应用iptables的修改<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo sysctl --system</span><br></pre></td></tr></table></figure></p>
<p>加载 br_netfilter 模块<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo lsmod | grep br_netfilter</span><br></pre></td></tr></table></figure></p>
<h3 id="配置k8s-master-节点"><a href="#配置k8s-master-节点" class="headerlink" title="配置k8s-master 节点"></a>配置k8s-master 节点</h3><p>本来应该使用命令，安装相关容器镜像<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo kubeadm config images pull</span><br></pre></td></tr></table></figure></p>
<p>可以通过下面命令查看需要安装哪些镜像<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm config images list</span><br></pre></td></tr></table></figure></p>
<p>###拉取镜像<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubeadm config images list |sed -e &apos;s/^/docker pull /g&apos; -e &apos;s#k8s.gcr.io#mirrorgooglecontainers#g&apos; |sh -x</span><br><span class="line">kubeadm config images list |sed -e &apos;s/^/docker pull /g&apos; -e &apos;s#k8s.gcr.io#docker.io/mirrorgooglecontainers#g&apos; |sh -x</span><br><span class="line">docker images |grep mirrorgooglecontainers |awk &apos;&#123;print &quot;docker tag &quot;,$1&quot;:&quot;$2,$1&quot;:&quot;$2&#125;&apos; |sed -e &apos;s#mirrorgooglecontainers#k8s.gcr.io#2&apos; |sh -x</span><br><span class="line">docker images |grep mirrorgooglecontainers |awk &apos;&#123;print &quot;docker rmi &quot;, $1&quot;:&quot;$2&#125;&apos; |sh -x</span><br></pre></td></tr></table></figure></p>
<p>###上面那段代码的工作就是下面这些工作<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">#/bin/bash</span><br><span class="line">docker pull mirrorgooglecontainers/kube-apiserver:v1.14.2 </span><br><span class="line">docker pull mirrorgooglecontainers/kube-controller-manager:v1.14.2</span><br><span class="line">docker pull mirrorgooglecontainers/kube-scheduler:v1.14.2</span><br><span class="line">docker pull mirrorgooglecontainers/kube-proxy:v1.14.2</span><br><span class="line">docker pull mirrorgooglecontainers/pause:3.1</span><br><span class="line">docker pull mirrorgooglecontainers/etcd:3.3.10</span><br><span class="line">docker pull coredns/coredns:1.3.1</span><br><span class="line">docker pull quay.io/coreos/flannel:v0.11.0-amd64</span><br><span class="line"></span><br><span class="line">docker tag mirrorgooglecontainers/kube-apiserver:v1.14.2 k8s.gcr.io/kube-apiserver:v1.14.2</span><br><span class="line">docker tag mirrorgooglecontainers/kube-controller-manager:v1.14.2 k8s.gcr.io/kube-controller-manager:v1.14.2</span><br><span class="line">docker tag mirrorgooglecontainers/kube-scheduler:v1.14.2 k8s.gcr.io/kube-scheduler:v1.14.2</span><br><span class="line">docker tag mirrorgooglecontainers/kube-proxy:v1.14.2 k8s.gcr.io/kube-proxy:v1.14.2</span><br><span class="line">docker tag mirrorgooglecontainers/pause:3.1 k8s.gcr.io/pause:3.1</span><br><span class="line">docker tag mirrorgooglecontainers/etcd:3.3.10 k8s.gcr.io/etcd:3.3.10</span><br><span class="line">docker tag coredns/coredns:1.3.1 k8s.gcr.io/coredns:1.3.1</span><br><span class="line"></span><br><span class="line">docker rmi mirrorgooglecontainers/kube-apiserver:v1.14.2</span><br><span class="line">docker rmi mirrorgooglecontainers/kube-controller-manager:v1.14.2</span><br><span class="line">docker rmi mirrorgooglecontainers/kube-scheduler:v1.14.2</span><br><span class="line">docker rmi mirrorgooglecontainers/kube-proxy:v1.14.2</span><br><span class="line">docker rmi mirrorgooglecontainers/pause:3.1</span><br><span class="line">docker rmi mirrorgooglecontainers/etcd:3.3.10</span><br><span class="line">docker rmi coredns/coredns:1.3.1</span><br></pre></td></tr></table></figure></p>
<p>###让我们开始集群设置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo kubeadm init --pod-network-cidr=10.244.0.0/16</span><br></pre></td></tr></table></figure></p>
<p>初始化完成之后，会如下反馈结果<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line">[init] Using Kubernetes version: v1.14.0</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">        [WARNING Firewalld]: firewalld is active, please ensure ports [6443 10250] are open or your cluster may not function correctly</span><br><span class="line">[preflight] Pulling images required for setting up a Kubernetes cluster</span><br><span class="line">[preflight] This might take a minute or two, depending on the speed of your internet connection</span><br><span class="line">[preflight] You can also perform this action in beforehand using &apos;kubeadm config images pull&apos;</span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[kubelet-start] Activating the kubelet service</span><br><span class="line">[certs] Using certificateDir folder &quot;/etc/kubernetes/pki&quot;</span><br><span class="line">[certs] Generating &quot;ca&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;apiserver&quot; certificate and key</span><br><span class="line">[certs] apiserver serving cert is signed for DNS names [k8s-master-node kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.0.120]</span><br><span class="line">[certs] Generating &quot;apiserver-kubelet-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;etcd/ca&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;etcd/server&quot; certificate and key</span><br><span class="line">[certs] etcd/server serving cert is signed for DNS names [k8s-master-node localhost] and IPs [192.168.0.120 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating &quot;etcd/peer&quot; certificate and key</span><br><span class="line">[certs] etcd/peer serving cert is signed for DNS names [k8s-master-node localhost] and IPs [192.168.0.120 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating &quot;etcd/healthcheck-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;apiserver-etcd-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;front-proxy-ca&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;front-proxy-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;sa&quot; key and public key</span><br><span class="line">[kubeconfig] Using kubeconfig folder &quot;/etc/kubernetes&quot;</span><br><span class="line">[kubeconfig] Writing &quot;admin.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;kubelet.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;controller-manager.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;scheduler.conf&quot; kubeconfig file</span><br><span class="line">[control-plane] Using manifest folder &quot;/etc/kubernetes/manifests&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-apiserver&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-controller-manager&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot;</span><br><span class="line">[etcd] Creating static Pod manifest for local etcd in &quot;/etc/kubernetes/manifests&quot;</span><br><span class="line">[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &quot;/etc/kubernetes/manifests&quot;. This can take up to 4m0s</span><br><span class="line">[apiclient] All control plane components are healthy after 16.501860 seconds</span><br><span class="line">[upload-config] storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace</span><br><span class="line">[kubelet] Creating a ConfigMap &quot;kubelet-config-1.14&quot; in namespace kube-system with the configuration for the kubelets in the cluster</span><br><span class="line">[upload-certs] Skipping phase. Please see --experimental-upload-certs</span><br><span class="line">[mark-control-plane] Marking the node k8s-master-node as control-plane by adding the label &quot;node-role.kubernetes.io/master=&apos;&apos;&quot;</span><br><span class="line">[mark-control-plane] Marking the node k8s-master-node as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span><br><span class="line">[bootstrap-token] Using token: 3j2pkk.xk7tnltycyz2xh5n</span><br><span class="line">[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster</span><br><span class="line">[bootstrap-token] creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace</span><br><span class="line">[addons] Applied essential addon: CoreDNS</span><br><span class="line">[addons] Applied essential addon: kube-proxy</span><br><span class="line"></span><br><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p $HOME/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="line"></span><br><span class="line">kubeadm join 192.168.2.163:6443 --token khm95w.mo0wwenu2o9hglls \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:aeb0ca593b63c8d674719858fd2397825825cebc552e3c165f00edb9671d6e32</span><br></pre></td></tr></table></figure></p>
<p>###最后那段 kubeadm join 的代码就是其他子节点连接master 使用的命令</p>
<p>###向常规用户添加集群设置，以便能够在本地访问kubernetes集群，执行下面的命令<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p $HOME/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure></p>
<p>###为pods应用网络设置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/a70459be0084506e4ec919aa1c114638878db11b/Documentation/kube-flannel.yml</span><br></pre></td></tr></table></figure></p>
<h2 id="k8s-node-工作节点"><a href="#k8s-node-工作节点" class="headerlink" title="k8s-node 工作节点"></a>k8s-node 工作节点</h2><p>下面这段命令就是 master kubeadm init 时生成的<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join 192.168.2.163:6443 --token khm95w.mo0wwenu2o9hglls \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:aeb0ca593b63c8d674719858fd2397825825cebc552e3c165f00edb9671d6e32</span><br></pre></td></tr></table></figure></p>
<h3 id="这个时候你可以通过检查节点状态"><a href="#这个时候你可以通过检查节点状态" class="headerlink" title="这个时候你可以通过检查节点状态"></a>这个时候你可以通过检查节点状态</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get nodes</span><br></pre></td></tr></table></figure>
<h3 id="由于kubeadm-join-会自动拉取两个镜像，谷歌镜像无法访问，需要手动拉取，不然这里该节点状态会一直显示-NotReady-状态-所以需要运行下面命令"><a href="#由于kubeadm-join-会自动拉取两个镜像，谷歌镜像无法访问，需要手动拉取，不然这里该节点状态会一直显示-NotReady-状态-所以需要运行下面命令" class="headerlink" title="由于kubeadm join 会自动拉取两个镜像，谷歌镜像无法访问，需要手动拉取，不然这里该节点状态会一直显示 NotReady 状态, 所以需要运行下面命令"></a>由于kubeadm join 会自动拉取两个镜像，谷歌镜像无法访问，需要手动拉取，不然这里该节点状态会一直显示 NotReady 状态, 所以需要运行下面命令</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">docker pull mirrorgooglecontainers/kube-proxy:v1.14.2</span><br><span class="line">docker pull mirrorgooglecontainers/pause:3.1</span><br><span class="line">docker tag mirrorgooglecontainers/kube-proxy:v1.14.2 k8s.gcr.io/kube-proxy:v1.14.2</span><br><span class="line">docker tag mirrorgooglecontainers/pause:3.1 k8s.gcr.io/pause:3.1</span><br><span class="line">docker rmi mirrorgooglecontainers/kube-proxy:v1.14.2</span><br><span class="line">docker rmi mirrorgooglecontainers/pause:3.1</span><br></pre></td></tr></table></figure>
<h3 id="防火墙设置"><a href="#防火墙设置" class="headerlink" title="防火墙设置"></a>防火墙设置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl disable firewalld &amp;&amp; sudo systemctl stop firewalld &amp;&amp; sudo systemctl status firewalld</span><br></pre></td></tr></table></figure>
<h2 id="上面主节点和子节点都已经安装完成"><a href="#上面主节点和子节点都已经安装完成" class="headerlink" title="上面主节点和子节点都已经安装完成"></a>上面主节点和子节点都已经安装完成</h2><h3 id="需要安装web管理端-安装到k8s-master"><a href="#需要安装web管理端-安装到k8s-master" class="headerlink" title="需要安装web管理端, 安装到k8s-master"></a>需要安装web管理端, 安装到k8s-master</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml</span><br></pre></td></tr></table></figure>
<h3 id="安装完成之后，kubernetes-dashboard端管理，登录可以使用三种方法登录：无密码登录，token登录，dashboard客户端查看，可以看这篇文章：点击传送过去"><a href="#安装完成之后，kubernetes-dashboard端管理，登录可以使用三种方法登录：无密码登录，token登录，dashboard客户端查看，可以看这篇文章：点击传送过去" class="headerlink" title="安装完成之后，kubernetes-dashboard端管理，登录可以使用三种方法登录：无密码登录，token登录，dashboard客户端查看，可以看这篇文章：点击传送过去."></a>安装完成之后，kubernetes-dashboard端管理，登录可以使用三种方法登录：无密码登录，token登录，dashboard客户端查看，可以看这篇文章：<a href="https://www.centos.bz/2018/07/kubernetes%E7%9A%84dashboard%E7%99%BB%E5%BD%95%E6%96%B9%E5%BC%8F/" target="_blank" rel="noopener">点击传送过去</a>.</h3><h3 id="如果登录kubernetes-dashboard之后，各种警告没有权限，请点击这篇文章点击传送过去"><a href="#如果登录kubernetes-dashboard之后，各种警告没有权限，请点击这篇文章点击传送过去" class="headerlink" title="如果登录kubernetes-dashboard之后，各种警告没有权限，请点击这篇文章点击传送过去"></a>如果登录kubernetes-dashboard之后，各种警告没有权限，请点击这篇文章<a href="https://www.jianshu.com/p/6f42ac331d8a" target="_blank" rel="noopener">点击传送过去</a></h3>
          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://labidc.github.io/2019/03/11/Spring-Cloud-之-Hystrix/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Labidc">
      <meta itemprop="description" content="喜欢研究技术的本质">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="老码的技术仓库">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/03/11/Spring-Cloud-之-Hystrix/" class="post-title-link" itemprop="url">Spring Cloud 之 Hystrix</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-03-11 21:56:38" itemprop="dateCreated datePublished" datetime="2019-03-11T21:56:38+08:00">2019-03-11</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-03-13 10:45:37" itemprop="dateModified" datetime="2019-03-13T10:45:37+08:00">2019-03-13</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Spring-Cloud/" itemprop="url" rel="index"><span itemprop="name">Spring Cloud</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>说到Spring Cloud就不得不想到 Netflix 公司, 因为该公司贡献出了微服务相关的很多开源项目。在这里我们今天来说说 Netflix 家族里的 <a href="https://github.com/Netflix/Hystrix" target="_blank" rel="noopener">Hystrix</a> ，<a href="https://github.com/Netflix/Hystrix/wiki/Configuration#fallback.isolation.semaphore.maxConcurrentRequests" target="_blank" rel="noopener">相关官方文档</a>. 我是一个使用任何一个中间件，都比较喜欢看官方文档的人, 因为官方的文档最权威</p>
<h2 id="一、为什么用Hystrix？"><a href="#一、为什么用Hystrix？" class="headerlink" title="一、为什么用Hystrix？"></a>一、为什么用Hystrix？</h2><h3 id="先看看Hystrix有些什么功能"><a href="#先看看Hystrix有些什么功能" class="headerlink" title="先看看Hystrix有些什么功能"></a>先看看Hystrix有些什么功能</h3><pre><code>1. 隔离 : 微服务调用下级服务过程中，下级服务故障或者响应能力不足造成整个系统崩溃, 隔离掉有问题的下级服务
2. 熔断 : 当失败率达到一定阈值时，熔断器触发，停止继续调用下级服务，并直接返回异常或者降级操作响应给客户，这是为了防止请求资源堵塞，起到了限流的作用。
3. 降级 : 当下级服务出现 网络原因、服务响应太慢、异常、的时候调用的补偿函数，不抛真实的异常信息给客户。
4. 缓存 : 设置一定的缓存策略，返回缓存数据
5. 合并请求: 当调用下级服务的时候，下级多次相同调用开销太大，可以合并请求批量调用。
6. 实时监控、报警: 监控服务调用情况。
</code></pre><h3 id="Hystrix-可以使用哪些方式支持熔断器？"><a href="#Hystrix-可以使用哪些方式支持熔断器？" class="headerlink" title="Hystrix 可以使用哪些方式支持熔断器？"></a>Hystrix 可以使用哪些方式支持熔断器？</h3><pre><code>1. 使用注解 @HystrixCommand 
2. 使用继承 HystrixCommands 和 HystrixObservableCommands 的实现
3. openfeign 中间件的 @FeignClient 用得最多的方式, 记得在配置文件设置 &apos;feign.hystrix.enabled=true&apos;
</code></pre><h2 id="二、知道了Hystrix的作用，那我们就需要了解如何用好它。"><a href="#二、知道了Hystrix的作用，那我们就需要了解如何用好它。" class="headerlink" title="二、知道了Hystrix的作用，那我们就需要了解如何用好它。"></a>二、知道了Hystrix的作用，那我们就需要了解如何用好它。</h2><h5 id="先描述一下可能出现的应用场景"><a href="#先描述一下可能出现的应用场景" class="headerlink" title="先描述一下可能出现的应用场景,"></a>先描述一下可能出现的应用场景,</h5><h5 id="以下环境：使用Spring-Boot-默认-WebServer-Tomcat"><a href="#以下环境：使用Spring-Boot-默认-WebServer-Tomcat" class="headerlink" title="以下环境：使用Spring Boot 默认 WebServer (Tomcat)"></a>以下环境：使用Spring Boot 默认 WebServer (Tomcat)</h5><pre class="mermaid">    graph LR
        start[用户请求某接口] --> input[微服务A]
        input -- 调用微服务B -->  B{微服务B}
        input -- 调用微服务C -->  C{微服务C}
        input -- 调用微服务D -->  D{微服务D}</pre>



<h5 id="当没有任何请求的情况下，-微服务A-Tomcat容器里的线程情况（10个名字-http-nio-“端口号”-exec-“线程流水号”）"><a href="#当没有任何请求的情况下，-微服务A-Tomcat容器里的线程情况（10个名字-http-nio-“端口号”-exec-“线程流水号”）" class="headerlink" title="当没有任何请求的情况下， 微服务A Tomcat容器里的线程情况（10个名字 http-nio-“端口号”-exec-“线程流水号”）"></a>当没有任何请求的情况下， 微服务A Tomcat容器里的线程情况（10个名字 http-nio-“端口号”-exec-“线程流水号”）</h5><p>   <img src="/2019/03/11/Spring-Cloud-之-Hystrix/tomcatnoquest.png" alt="微服务A"></p>
<h5 id="好了，基本情况描述完了，现在讲讲如何使用，用好任何中间件，一定要搞清楚每个配置的作用"><a href="#好了，基本情况描述完了，现在讲讲如何使用，用好任何中间件，一定要搞清楚每个配置的作用" class="headerlink" title="好了，基本情况描述完了，现在讲讲如何使用，用好任何中间件，一定要搞清楚每个配置的作用"></a>好了，基本情况描述完了，现在讲讲如何使用，用好任何中间件，一定要搞清楚每个配置的作用</h5><blockquote>
<h2 id="配置文件方式有两种"><a href="#配置文件方式有两种" class="headerlink" title="配置文件方式有两种"></a>配置文件方式有两种</h2><ol>
<li>第一种：全局默认设置<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">hystrix.command.default.后面的相关配置</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
</blockquote>
<blockquote>
<ol start="2">
<li>第二种：针对设置了自定义HystrixCommandKey的Hystrix方法<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">hystrix.command.HystrixCommandKey.后面的相关配置</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
</blockquote>
<blockquote>
</blockquote>
<hr>
<h2 id="正式开始，以全局默认配置的范例来讲解。"><a href="#正式开始，以全局默认配置的范例来讲解。" class="headerlink" title="正式开始，以全局默认配置的范例来讲解。"></a>正式开始，以全局默认配置的范例来讲解。</h2><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">hystrix.command.default.execution.isolation.strategy</span></span><br></pre></td></tr></table></figure>
<p>该设置是熔断器的运行模式，有THREAD, SEMAPHORE两种，默认是THREAD模式，现在用Jmeter模拟每秒并发20个请求,看看在 THREAD, SEMAPHORE和模式下有什么不同, <strong>微服务A</strong> 的Tomcat里的线程情况</p>
<h5 id="首先-Tomcat的工作线程数量20"><a href="#首先-Tomcat的工作线程数量20" class="headerlink" title="首先 Tomcat的工作线程数量20"></a>首先 Tomcat的工作线程数量20</h5><p><img src="/2019/03/11/Spring-Cloud-之-Hystrix/tomcatrquest20.png" alt="微服务A"></p>
<h5 id="THREAD-模式下，Hystrix为每个下级服务的调用生成了多个线程-hystrix-“微服务名称”-线程流水号-与-Hystrix-Timer-线程流水号-的相关线程"><a href="#THREAD-模式下，Hystrix为每个下级服务的调用生成了多个线程-hystrix-“微服务名称”-线程流水号-与-Hystrix-Timer-线程流水号-的相关线程" class="headerlink" title="THREAD 模式下，Hystrix为每个下级服务的调用生成了多个线程 hystrix-“微服务名称”-线程流水号 与 Hystrix-Timer-线程流水号  的相关线程"></a>THREAD 模式下，Hystrix为每个下级服务的调用生成了多个线程 hystrix-“微服务名称”-线程流水号 与 Hystrix-Timer-线程流水号  的相关线程</h5><p><img src="/2019/03/11/Spring-Cloud-之-Hystrix/THREAD.png" alt="微服务A"></p>
<h5 id="SEMAPHORE-模式下只生成-Hystrix-Timer-线程流水号-的相关线程"><a href="#SEMAPHORE-模式下只生成-Hystrix-Timer-线程流水号-的相关线程" class="headerlink" title="SEMAPHORE 模式下只生成 Hystrix-Timer-线程流水号 的相关线程"></a>SEMAPHORE 模式下只生成 Hystrix-Timer-线程流水号 的相关线程</h5><p><img src="/2019/03/11/Spring-Cloud-之-Hystrix/SEMAPHORE.png" alt="微服务A"></p>
<blockquote>
<h2 id="以上现象印证了官网文档里的配图"><a href="#以上现象印证了官网文档里的配图" class="headerlink" title="以上现象印证了官网文档里的配图"></a>以上现象印证了官网文档里的配图</h2><ol>
<li>在THREAD模式下，新开了线程调用下级服务，这样对下级服务调用的“线程超时时间”更可控。<br>“线程超时时间”&gt;=“网络连接时间”+“请求响应时间”, 如果你使用的@FeignClient，Feign默认使用的是ribbon, 尝试配置ribbon.ConnectTimeout 连接超时时间和 ribbon.ReadTimeout 响应超时时间。ribbon 的超时会直接影响Hystrix触发</li>
<li>在SEMAPHORE（信号量，多线程开发经验丰富的同学都已经很熟悉了）模式下，是使用的Tomcat的工作线程直接同步阻塞调用的下级服务，和没有开启Hystrix下的调用原理相同<br>Hystrix-Timer-线程流水号 是用来管理上面两种模式的计时器线程。</li>
<li>总结：官网也是说了 hystrixcommands 适合 THREAD 模式，当每秒数百个请求的时候，同时方法里调用下级服务又比较多的情况下是成倍数增长，比较占用服务器资源，资源的占用有可能造成频繁的GC回收，以后有机会讲讲JVM相关原理，GC回收是需要重视的，而且线程太多，线程上下文环境的切换也是相当头痛的。SEMAPHORE 模式适合 HystrixObservableCommands 调用，使用Tomcat工作线程进行批量处理工作。</li>
</ol>
</blockquote>
<hr>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds</span></span><br></pre></td></tr></table></figure>
<h5 id="现在我改一下上面的图，模拟下层服务的响应延迟-比如数据库IO堵塞"><a href="#现在我改一下上面的图，模拟下层服务的响应延迟-比如数据库IO堵塞" class="headerlink" title="现在我改一下上面的图，模拟下层服务的响应延迟(比如数据库IO堵塞)"></a>现在我改一下上面的图，模拟下层服务的响应延迟(比如数据库IO堵塞)</h5><pre class="mermaid">    graph LR
        start[用户请求某接口] --> input[微服务A,设置timeoutInMilliseconds=1000]
        input -- 调用微服务B -->  B{微服务B,线程延迟2秒}
        input -- 调用微服务C -->  C{微服务C,线程延迟2秒}
        input -- 调用微服务D -->  D{微服务D,线程延迟2秒}</pre>


<blockquote>
<h2 id="该设置是线程超时时间，也就是由-“Hystrix-Timer-线程流水号”-线程来管理的"><a href="#该设置是线程超时时间，也就是由-“Hystrix-Timer-线程流水号”-线程来管理的" class="headerlink" title="该设置是线程超时时间，也就是由 “Hystrix-Timer-线程流水号” 线程来管理的"></a>该设置是线程超时时间，也就是由 “Hystrix-Timer-线程流水号” 线程来管理的</h2><ol>
<li>在THREAD模式下，更可控。<br>如果 timeoutInMilliseconds 设置1秒超时，下级服务的2秒延迟，三个下级服务都会线程超时，最后微服务A调用时间为 3个服务*1秒=3秒<br>但是由于线程模式是独立线程跑下级服务调用，可以理解是一种异步调用。我测试了每秒20个并发，微服务A调用这三个服务的函数执行平均时间是1-3秒之间完成。</li>
<li>在SEMAPHORE下，就是另外一种现象，因为信号量的模式是直接使用Tomcat的工作线程去请求下级服务，最后微服务A调用时间应该是 3个服务*2秒=6秒，我同样测试了每秒20个并发，实际效果是平均4-6秒。</li>
<li>总结：也就是说THREAD模式下线程的中断更可控而且独立并行，就是拿空间换时间。不要小看这几秒的差距，当下级服务处理能力较差的情况下，可以大大提高吞吐量。</li>
</ol>
</blockquote>
<hr>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">hystrix.command.default.execution.timeout.enabled</span></span><br></pre></td></tr></table></figure>
<p>  该设置是打开或者关闭线程超时的开关，如果关闭之后，在Tomcat容器中看不到 Hystrix-Timer-线程流水号 的相关线程了，<br>  上面的 timeoutInMilliseconds 设置直接无效。</p>
<hr>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">hystrix.command.default.execution.isolation.thread.interruptOnTimeout</span></span><br></pre></td></tr></table></figure>
<p>  该设置默认值是true, 当timeoutInMilliseconds时间超时之后，直接中断调用线程，经过前面的实验中断和不中断在最终执行时间应该是有区别的。我尝试关闭该设置，实际上平均调用时间没什么多大差别。</p>
<hr>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">hystrix.command.default.execution.isolation.thread.interruptOnCancel</span></span><br></pre></td></tr></table></figure>
<p>  该设置从官方文档来讲是当取消请求的时候中断线程，我尝试了各种实验方式都没有效果，于是搜索GitHub上的源码，想看看到底有什么操作，结果搜索到另外一个答案<br>  <a href="https://github.com/Netflix/Hystrix/issues/1650" target="_blank" rel="noopener">https://github.com/Netflix/Hystrix/issues/1650</a><br>  官方回答还没有实现该功能，只是为了向后兼容做铺垫预留的一个配置</p>
<hr>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">hystrix.command.default.execution.isolation.semaphore.maxConcurrentRequests</span></span><br></pre></td></tr></table></figure>
<p>   该设置只在SEMAPHORE下有效，默认值是10，也就是利用信号量机制最大能同时执行10个请求，当瞬间超过10个并发的时候，就返回调用降级操作了。</p>
<hr>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">hystrix.command.default.fallback.isolation.semaphore.maxConcurrentRequests</span></span><br></pre></td></tr></table></figure>
<p>   该设置官方文档说支持SEMAPHORE和THREAD模式，也就是当大量降级操作调用大于maxConcurrentRequests时，直接返回异常给客户端了。<br>   我尝试把这个值设置成1，能查看到一种异常现象<br>   com.netflix.hystrix.exception.HystrixRuntimeException:  fallback execution rejected.<br>   这是为了保护服务器资源被大量占用。</p>
<hr>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">hystrix.command.default.fallback.enabled</span></span><br></pre></td></tr></table></figure>
<p>  该设置是打开和关闭降级操作，当下级服务调用出现超时、异常等情况就直接抛出异常给客户，不会做降级处理。</p>
<hr>
<h2 id="下面开始才是真正的熔断器配置"><a href="#下面开始才是真正的熔断器配置" class="headerlink" title="下面开始才是真正的熔断器配置"></a>下面开始才是真正的熔断器配置</h2><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">hystrix.command.default.circuitBreaker.enabled</span></span><br></pre></td></tr></table></figure>
<p>  熔断的含义就是当服务器请求达到一定负载之后（大量错误或超时请求），暂时性直接拒绝所有请求。<br>  高并发的情况下，可以有效防止雪崩，雪崩的含义就是服务本来正常情况下可以保证稳定吞吐一定的并发请求，当大量并发的时候资源被占用，造成堵塞，无法保证基础的吞吐量，严重情况甚至会JVM崩溃。</p>
<hr>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">hystrix.command.default.circuitBreaker.requestVolumeThreshold</span></span><br><span class="line"><span class="string">hystrix.command.default.circuitBreaker.errorThresholdPercentage</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p> 这两个配置要一起讲</p>
<ol>
<li>requestVolumeThreshold 当并发在窗口时间内出现了requestVolumeThreshold次错误就开启熔断器, 这个所谓窗口时间没有看找到相关配置，官方说明是10秒。</li>
<li>errorThresholdPercentage 当错误率达到一定百分比启动熔断</li>
</ol>
</blockquote>
<hr>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">hystrix.command.default.circuitBreaker.forceOpen</span></span><br><span class="line"><span class="string">hystrix.command.default.circuitBreaker.forceClosed</span></span><br></pre></td></tr></table></figure>
<p> 设置是强制打开熔断器和强制关闭熔断器</p>
<hr>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">hystrix.command.default.circuitBreaker.sleepWindowInMilliseconds</span></span><br></pre></td></tr></table></figure>
<p>当熔断器打开后会直接响应所有请求，此时间是配置多少时间之后再次尝试重新处理请求</p>
<hr>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">Metrics</span> <span class="string">相关配置</span></span><br></pre></td></tr></table></figure>
<p>hystrix 自带一个看板插件，可以查看熔断器的工作情况与一些统计数据。metrics properties.主要用于统计配置执行情况 提供给看板插件使用，这里就不详细多讲了</p>
<hr>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">Request</span> <span class="string">Context</span> <span class="string">相关配置</span></span><br></pre></td></tr></table></figure>
<p>请求缓存和日志相关的配置，也不多讲了，小伙伴们可以自行百度或谷歌使用方法</p>
<hr>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">Collapser</span> <span class="string">Properties</span> <span class="string">相关配置</span></span><br></pre></td></tr></table></figure>
<p>如果你某接口并发比较高，你可以尝试合并请求的方式调用，该配置大家也可以自行百度或谷歌使用方法</p>
<hr>
<h2 id="Thread-Pool-Properties-线程池配置，看官方文档的介绍，应该只支持THREAD模式"><a href="#Thread-Pool-Properties-线程池配置，看官方文档的介绍，应该只支持THREAD模式" class="headerlink" title="Thread Pool Properties 线程池配置，看官方文档的介绍，应该只支持THREAD模式"></a>Thread Pool Properties 线程池配置，看官方文档的介绍，应该只支持THREAD模式</h2><p>官方文档介绍到其实当您正确配置时，hystrixcommand 超时应该情况应该不太会出现，但是如果不是网络延迟影响时间，或者在最坏的情况下，connect+read+retry+connect+read，注意这里提到了重试，我没有尝试实验该重试机制，我个人的理解是该重试应该是connect失败的情况的会重试，不然下级服务需要处理冥等性问题<br><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">hystrix.threadpool.default.coreSize</span></span><br><span class="line"><span class="string">hystrix.threadpool.default.allowMaximumSizeToDivergeFromCoreSize</span></span><br><span class="line"><span class="string">hystrix.threadpool.default.maximumSize</span></span><br><span class="line"><span class="string">hystrix.threadpool.default.keepAliveTimeMinutes</span></span><br></pre></td></tr></table></figure></p>
<p>coreSize 该默认值是5，也就是 hystrix-“微服务名称”-线程流水号 的数量。<br>allowMaximumSizeToDivergeFromCoreSize 该设置表示是否开启弹性线程创建<br>maximumSize设置大于coreSize 同时 allowMaximumSizeToDivergeFromCoreSize 开启之后，maximumSize-coreSize=可以弹性创建的线程数<br>keepAliveTimeMinutes 当弹性线程创建出来之后，挂起未运行超过 keepAliveTimeMinutes 分钟之后就回收掉</p>
<hr>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">hystrix.threadpool.default.maxQueueSize</span></span><br><span class="line"><span class="string">hystrix.threadpool.default.queueSizeRejectionThreshold</span></span><br></pre></td></tr></table></figure>
<p>maxQueueSize 默认值是-1, 因此线程池的工作模式是 SynchronousQueue（同步队列） 永远只会有一个消费对象，也就是生产者存一个，消费者取一下的模式，如果消费者处理太慢，就会出现堵塞情况并拒绝响应请求。 maxQueueSize设置大于0的任何值，则表示线程池工作模式为LinkedBlockingQueue(阻塞队列), maxQueueSize 则表示阻塞队列里的等待队列的长度，大量并发情况下如果等待队列里没有位置了，无法进入队列的请求直接拒绝响应。<br>queueSizeRejectionThreshold 设置拒绝队列的长度，即使maxQueueSize的值没有达到，达到queueSizeRejectionThreshold该值也直接决绝响应，该值主要是为了动态调整maxQueueSize的大小做的一个补偿方案。<br>上面提到的拒绝响应会直接调用降级操作，不是直接返回异常。</p>
<hr>
<h2 id="前面提到了降级操作，如果是FeignClient-有两种降级函数的写法"><a href="#前面提到了降级操作，如果是FeignClient-有两种降级函数的写法" class="headerlink" title="前面提到了降级操作，如果是FeignClient, 有两种降级函数的写法"></a>前面提到了降级操作，如果是FeignClient, 有两种降级函数的写法</h2><blockquote>
<ol>
<li>fallback 不关心降级发生原因，统一处理。</li>
<li>fallbackFactory 可以获取降级操作是什么异常造成，根据情况的不同做不同的处理。</li>
<li>总结： 降级其实可以做很多事情，比如返回友好错误响应给客户、根据不同的异常情况做相关处理，比如：写日志，或者一些补偿性数据库操作。</li>
</ol>
</blockquote>
<h1 id="最后总结一下，Hystrix-该不该用完全看你项目的需要，如何用也是看你的项目需要，相关配置绝对不是设置越大越多就好，合适的设置才是正确的，后面有时间我会分享JVM一些原理来解释一下原因。"><a href="#最后总结一下，Hystrix-该不该用完全看你项目的需要，如何用也是看你的项目需要，相关配置绝对不是设置越大越多就好，合适的设置才是正确的，后面有时间我会分享JVM一些原理来解释一下原因。" class="headerlink" title="最后总结一下，Hystrix 该不该用完全看你项目的需要，如何用也是看你的项目需要，相关配置绝对不是设置越大越多就好，合适的设置才是正确的，后面有时间我会分享JVM一些原理来解释一下原因。"></a>最后总结一下，Hystrix 该不该用完全看你项目的需要，如何用也是看你的项目需要，相关配置绝对不是设置越大越多就好，合适的设置才是正确的，后面有时间我会分享JVM一些原理来解释一下原因。</h1>
          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://labidc.github.io/2019/03/08/hello-world/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Labidc">
      <meta itemprop="description" content="喜欢研究技术的本质">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="老码的技术仓库">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/03/08/hello-world/" class="post-title-link" itemprop="url">Hello World</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-03-08 11:36:52" itemprop="dateCreated datePublished" datetime="2019-03-08T11:36:52+08:00">2019-03-08</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-03-13 09:16:35" itemprop="dateModified" datetime="2019-03-13T09:16:35+08:00">2019-03-13</time>
              
            
          </span>

          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>这是我编码10多年来第一次自己搭建博客，希望大家支持。在这里更多是分享一些我对技术的理解，欢迎相互交流与学习。<br>这个世界上没有完美的程序，更没有无敌的程序猿，只有相互学习，取长补短才能进步。</p>
<h2 id="谦虚待人，对技术有敬畏之心"><a href="#谦虚待人，对技术有敬畏之心" class="headerlink" title="谦虚待人，对技术有敬畏之心"></a>谦虚待人，对技术有敬畏之心</h2><h2 id="了解技术的本质才能更好用好它。"><a href="#了解技术的本质才能更好用好它。" class="headerlink" title="了解技术的本质才能更好用好它。"></a>了解技术的本质才能更好用好它。</h2>
          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Labidc</p>
              <div class="site-description motion-element" itemprop="description">喜欢研究技术的本质</div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">5</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">2</span>
                    <span class="site-state-item-name">分类</span>
                  
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">3</span>
                    <span class="site-state-item-name">标签</span>
                  
                </div>
              
            </nav>
          

          

          

          

          
          

          
            
          
          

        </div>
      </div>

      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Labidc</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.0.1</div>





  <script src="https://unpkg.com/mermaid@<%= theme.mermaid.version %>/dist/mermaid.min.js"></script>
  <script>
    if (window.mermaid) {
      mermaid.initialize({theme: 'forest'});
    }
  </script>


        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="post-meta-item-icon">
      <i class="fa fa-user"></i>
    </span>
    <span class="site-uv" title="总访客量">
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="post-meta-divider">|</span>
  

  
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" title="总访问量">
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/src/utils.js?v=7.0.1"></script>

  <script src="/js/src/motion.js?v=7.0.1"></script>



  
  


  <script src="/js/src/affix.js?v=7.0.1"></script>

  <script src="/js/src/schemes/pisces.js?v=7.0.1"></script>



  

  


  <script src="/js/src/next-boot.js?v=7.0.1"></script>


  

  

  

  



  




  

  

  

  

  
<script>
if ($('body').find('pre.mermaid').length) {
  $.ajax({
    type: 'GET',
    url: '//cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js',
    dataType: 'script',
    cache: true,
    success: function() {
      mermaid.initialize({
        theme: 'forest',
        logLevel: 3,
        flowchart: { curve: 'linear' },
        gantt: { axisFormat: '%m/%d/%Y' },
        sequence: { actorMargin: 50 }
      });
    }
  });
}
</script>


  

  

  

  

  

  

  

</body>
</html>
